import scrapy
from urllib.parse import urljoin
from datetime import datetime
from sb_scraper.items import ProductItem
from sb_scraper.spiders.utils import to_number, table_to_dict, kv_from_table, extract_variants, absolutize_all

class SBCatalogSpider(scrapy.Spider):
    name = "sb_catalog"
    allowed_domains = ["simplybearings.co.uk"]
    start_urls = ["https://www.simplybearings.co.uk/"]

    custom_settings = {
        # "FEEDS": {"out/products.ndjson": {"format":"jsonlines", "encoding":"utf8"}},
    }

    def parse(self, response):
        # Discover category and subcategory links
        anchors = response.css("a::attr(href)").getall()
        for href in anchors:
            url = urljoin(response.url, href)
            if self.is_category(url):
                yield scrapy.Request(url, callback=self.parse_category)

    def is_category(self, url: str) -> bool:
        # TODO: adjust after inspecting real paths
        lowered = url.lower()
        return any(seg in lowered for seg in ["/shop", "/category", "/bearings"])

    def parse_category(self, response):
        # Product links (adjust selectors to site structure)
        product_links = response.css("a.product-link::attr(href)").getall()
        if not product_links:
            product_links = [u for u in response.css("a::attr(href)").getall() if any(seg in u.lower() for seg in ["/product", "/p/","/sku="])]

        for href in product_links:
            url = urljoin(response.url, href)
            yield scrapy.Request(url, callback=self.parse_product, cb_kwargs={
                "category_breadcrumbs": [t.strip() for t in response.css("nav.breadcrumb *::text").getall() if t.strip()]
            })

        # Pagination
        next_page = response.css("a.next::attr(href), li.pagination-next a::attr(href)").get()
        if next_page:
            yield scrapy.Request(urljoin(response.url, next_page), callback=self.parse_category)

        # Recurse into deeper subcategories
        subcats = response.css("a.category::attr(href), .subcategory a::attr(href)").getall()
        for href in subcats:
            url = urljoin(response.url, href)
            yield scrapy.Request(url, callback=self.parse_category)

    def parse_product(self, response, category_breadcrumbs=None):
        title = response.css("h1::text").get() or response.css("meta[property='og:title']::attr(content)").get()
        price_candidate = response.css(".price::text, .product-price::text, [itemprop='price']::attr(content)").get()
        sku_candidate = response.css("[itemprop='sku']::text, .sku::text").get()
        if not (title and (price_candidate or sku_candidate)):
            return

        item = ProductItem()
        item["product_url"] = response.url
        item["breadcrumbs"] = category_breadcrumbs or [t.strip() for t in response.css("nav.breadcrumb *::text").getall() if t.strip()]
        item["title"] = title.strip()

        item["price"] = to_number(price_candidate)
        item["currency"] = response.css("[itemprop='priceCurrency']::attr(content)").get() or "GBP"
        list_price_text = response.css(".rrp::text, .list-price::text").get()
        item["list_price"] = to_number(list_price_text) if list_price_text else None

        item["sku"] = sku_candidate
        item["mpn"] = kv_from_table(response, keys=("MPN", "Manufacturer Part Number"))
        item["ean"] = kv_from_table(response, keys=("EAN", "Barcode", "GTIN"))

        item["brand"] = response.css("[itemprop='brand']::attr(content), .brand::text").get()

        stock_text = " ".join(response.css(".stock, .availability, .in-stock::text").getall()).lower()
        item["in_stock"] = ("in stock" in stock_text) or ("available" in stock_text and "out" not in stock_text) or None

        attrs = table_to_dict(response)
        item["attributes"] = attrs if attrs else None
        item["dimensions"] = {
            "id": attrs.get("Inner Diameter") or attrs.get("ID") if attrs else None,
            "od": attrs.get("Outer Diameter") or attrs.get("OD") if attrs else None,
            "width": attrs.get("Width") if attrs else None,
        }

        item["variants"] = extract_variants(response) or None

        item["images"] = absolutize_all(response.url, response.css("img.product-image::attr(src), .gallery img::attr(src)").getall())
        item["documents"] = absolutize_all(response.url, response.css("a[href$='.pdf']::attr(href)").getall())

        if item.get("breadcrumbs"):
            crumbs = [c for c in item["breadcrumbs"] if c and c.lower() not in ("home",)]
            item["category"] = crumbs[0] if len(crumbs) >= 1 else None
            item["subcategory"] = crumbs[1] if len(crumbs) >= 2 else None

        ship = " ".join(response.css(".shipping *::text").getall()).strip()
        item["shipping_info"] = ship if ship else None
        lead = " ".join(response.css(".lead-time *::text").getall()).strip()
        item["lead_time"] = lead if lead else None

        item["last_seen_at"] = datetime.utcnow().isoformat()
        yield item